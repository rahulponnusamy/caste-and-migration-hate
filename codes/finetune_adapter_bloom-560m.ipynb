{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets peft scikit-learn\n",
    "# ! pip install matplotlib\n",
    "# ! pip install -U adapters\n",
    "\n",
    "\n",
    "#########  Not necessary  #############\n",
    "# ! pip install --upgrade transformers\n",
    "# ! pip install -U accelerate\n",
    "# ! pip install -U transformers\n",
    "# ! pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rahpon/projects/caste\n",
      "/home/rahpon/projects/caste\n"
     ]
    }
   ],
   "source": [
    "#  Setting the working directory\n",
    "import os\n",
    "if os.getcwd() != '/home/rahpon/projects/caste':\n",
    "    os.chdir('/home/rahpon/projects/caste')\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "\n",
    "# df1 = pd.read_csv('DataSplit/bloom/train.csv')\n",
    "# df2 = pd.read_csv('DataSplit/bloom/val.csv')\n",
    "# df3 = pd.read_csv('DataSplit/bloom/test.csv')\n",
    "\n",
    "\n",
    "# dict1 = df1.to_dict('records')\n",
    "# dict2 = df2.to_dict('records')\n",
    "# dict3 = df3.to_dict('records')\n",
    "\n",
    "\n",
    "# merged_dict = {'train': dict1, 'val': dict2, 'test': dict3}\n",
    "\n",
    "# with open('DataSplit/bloom/merged.json', 'w') as f:\n",
    "#     json.dump(merged_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Open the JSON file\n",
    "# with open('DataSplit/merged.json','r') as f:\n",
    "#     # Load the JSON data from the file\n",
    "#     data1 = json.load(f)\n",
    "\n",
    "# print(data1['train'][0])\n",
    "\n",
    "# data_path = 'DataSplit/merged.json'\n",
    "\n",
    "# if data_path.endswith(\".json\"):  # todo: support jsonl\n",
    "#     data2 = load_dataset(\"json\", data_files=data_path)\n",
    "#     print('yes')\n",
    "# else:\n",
    "#     data2 = load_dataset(data_path)\n",
    "#     print('no')\n",
    "# print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import fire\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "\"\"\"\n",
    "Unused imports:\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "\"\"\"\n",
    "sys.path.append(os.path.join(os.getcwd(), \"LLM-Adapters/peft/src\"))\n",
    "\n",
    "from peft import (  # noqa: E402\n",
    "    LoraConfig,\n",
    "    BottleneckConfig,\n",
    "    PrefixTuningConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, AutoModel  # noqa: F402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    # if data_point[\"text\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "\n",
    "                ### Instruction:\n",
    "                {data_point[\"instruction\"]}\n",
    "                \n",
    "                ### Input:\n",
    "                {data_point[\"texts\"]}\n",
    "                \n",
    "                ### Response:\n",
    "                {data_point[\"labels\"]}\"\"\" # noqa: E501\n",
    "    # else:\n",
    "    #     return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.  \n",
    "\n",
    "    #             ### Instruction:\n",
    "    #             {data_point[\"instruction\"]}\n",
    "                \n",
    "    #             ### Response:\n",
    "    #             {data_point[\"label\"]}\"\"\" # noqa: E501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_prompt(data_point):\n",
    "#     try:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \n",
    "\n",
    "#                 ### Instruction:\n",
    "#                 {data_point[\"instruction\"]}\n",
    "\n",
    "#                 ### Input:\n",
    "#                 {data_point[\"texts\"]}\n",
    "\n",
    "#                 ### Response:\n",
    "#                 {data_point[\"labels\"]}\"\"\"\n",
    "#     except KeyError as e:\n",
    "#         print(f\"KeyError: {e}\")\n",
    "#         print(f\"Available keys: {data_point.keys()}\")\n",
    "#         raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        # model/data params\n",
    "        base_model: str = \"\",  # the only required argument\n",
    "        data_path: str = \"yahma/alpaca-cleaned\",\n",
    "        output_dir: str = \"./lora-alpaca\",\n",
    "        adapter_name: str = \"bottleneck\",\n",
    "        load_8bit : bool = False,\n",
    "        # training hyperparams\n",
    "        batch_size: int = 8,\n",
    "        micro_batch_size: int = 4,\n",
    "        num_epochs: int = 3,\n",
    "        learning_rate: float = 3e-4,\n",
    "        cutoff_len: int = 256,\n",
    "        val_set_size: int = 2000,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "        eval_step: int = 200,\n",
    "        save_step: int = 1000,\n",
    "        # lora hyperparams\n",
    "        lora_r: int = 8,\n",
    "        lora_alpha: int = 16,\n",
    "        lora_dropout: float = 0.05,\n",
    "        lora_target_modules: List[str] = None,\n",
    "        # bottleneck adapter hyperparams\n",
    "        bottleneck_size: int = 256,\n",
    "        non_linearity: str = \"tanh\",\n",
    "        adapter_dropout: float = 0.0,\n",
    "        use_parallel_adapter: bool = False,\n",
    "        use_adapterp: bool = False,\n",
    "        target_modules: List[str] = None,\n",
    "        scaling: Union[float, str] = 1.0,\n",
    "        # prefix tuning hyperparams\n",
    "        num_virtual_tokens: int = 30,\n",
    "        # llm hyperparams\n",
    "        train_on_inputs: bool = True,  # if False, masks out inputs in loss\n",
    "        group_by_length: bool = False,  # faster, but produces an odd training loss curve\n",
    "        # wandb params\n",
    "        wandb_project: str = \"\",\n",
    "        wandb_run_name: str = \"\",\n",
    "        wandb_watch: str = \"\",  # options: false | gradients | all\n",
    "        wandb_log_model: str = \"\",  # options: false | true\n",
    "        resume_from_checkpoint: str = None,  # either training checkpoint or final adapter\n",
    "):\n",
    "    print(\n",
    "        f\"Finetuning model with params:\\n\"\n",
    "        f\"base_model: {base_model}\\n\"\n",
    "        f\"data_path: {data_path}\\n\"\n",
    "        f\"output_dir: {output_dir}\\n\"\n",
    "        f\"batch_size: {batch_size}\\n\"\n",
    "        f\"micro_batch_size: {micro_batch_size}\\n\"\n",
    "        f\"num_epochs: {num_epochs}\\n\"\n",
    "        f\"learning_rate: {learning_rate}\\n\"\n",
    "        f\"cutoff_len: {cutoff_len}\\n\"\n",
    "        f\"val_set_size: {val_set_size}\\n\"\n",
    "        f\"use_gradient_checkpointing: {use_gradient_checkpointing}\\n\"\n",
    "        f\"lora_r: {lora_r}\\n\"\n",
    "        f\"lora_alpha: {lora_alpha}\\n\"\n",
    "        f\"lora_dropout: {lora_dropout}\\n\"\n",
    "        f\"lora_target_modules: {lora_target_modules}\\n\"\n",
    "        f\"bottleneck_size: {bottleneck_size}\\n\"\n",
    "        f\"non_linearity: {non_linearity}\\n\"\n",
    "        f\"adapter_dropout: {adapter_dropout}\\n\"\n",
    "        f\"use_parallel_adapter: {use_parallel_adapter}\\n\"\n",
    "        f\"use_adapterp: {use_adapterp}\\n\"\n",
    "        f\"train_on_inputs: {train_on_inputs}\\n\"\n",
    "        f\"scaling: {scaling}\\n\"\n",
    "        f\"adapter_name: {adapter_name}\\n\"\n",
    "        f\"target_modules: {target_modules}\\n\"\n",
    "        f\"group_by_length: {group_by_length}\\n\"\n",
    "        f\"wandb_project: {wandb_project}\\n\"\n",
    "        f\"wandb_run_name: {wandb_run_name}\\n\"\n",
    "        f\"wandb_watch: {wandb_watch}\\n\"\n",
    "        f\"wandb_log_model: {wandb_log_model}\\n\"\n",
    "        f\"resume_from_checkpoint: {resume_from_checkpoint}\\n\"\n",
    "    )\n",
    "    assert (\n",
    "        base_model\n",
    "    ), \"Please specify a --base_model, e.g. --base_model='decapoda-research/llama-7b-hf'\"\n",
    "    gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "\n",
    "    device_map = \"auto\"\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    ddp = world_size != 1\n",
    "    if ddp:\n",
    "        device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps // world_size\n",
    "\n",
    "    # Check if parameter passed or if set within environ\n",
    "    use_wandb = len(wandb_project) > 0 or (\n",
    "            \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n",
    "    )\n",
    "    # Only overwrite environ if wandb param passed\n",
    "    if len(wandb_project) > 0:\n",
    "        os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "    if len(wandb_watch) > 0:\n",
    "        os.environ[\"WANDB_WATCH\"] = wandb_watch\n",
    "    if len(wandb_log_model) > 0:\n",
    "        os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model\n",
    "\n",
    "    if load_8bit:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model,\n",
    "            load_in_8bit=load_8bit,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=device_map,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model,\n",
    "            load_in_8bit=False,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map={\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)},\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "    if model.config.model_type == \"llama\":\n",
    "        # Due to the name of transformers' LlamaTokenizer, we have to do this\n",
    "        tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "\n",
    "    tokenizer.pad_token_id = (\n",
    "        0  # unk. we want this to be different from the eos token\n",
    "    )\n",
    "    tokenizer.padding_side = \"left\"  # Allow batched inference\n",
    "\n",
    "    def tokenize(prompt, add_eos_token=True):\n",
    "        # there's probably a way to do this with the tokenizer settings\n",
    "        # but again, gotta move fast\n",
    "        result = tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=cutoff_len,\n",
    "            padding=False,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        if (\n",
    "                result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "                and len(result[\"input_ids\"]) < cutoff_len\n",
    "                and add_eos_token\n",
    "        ):\n",
    "            result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "            if \"chatglm\" not in base_model:\n",
    "                result[\"attention_mask\"].append(1)\n",
    "\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "        if \"chatglm\" in base_model:\n",
    "            return {\"input_ids\": result[\"input_ids\"], \"labels\": result[\"labels\"]}\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def generate_and_tokenize_prompt(data_point):\n",
    "        full_prompt = generate_prompt(data_point)\n",
    "        tokenized_full_prompt = tokenize(full_prompt)\n",
    "        if not train_on_inputs:\n",
    "            user_prompt = generate_prompt({**data_point, \"output\": \"\"})\n",
    "            tokenized_user_prompt = tokenize(user_prompt, add_eos_token=False)\n",
    "            user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "            tokenized_full_prompt[\"labels\"] = [\n",
    "                                                  -100\n",
    "                                              ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "                                                                    user_prompt_len:\n",
    "                                                                    ]  # could be sped up, probably\n",
    "        return tokenized_full_prompt\n",
    "\n",
    "    model = prepare_model_for_int8_training(model, use_gradient_checkpointing=use_gradient_checkpointing)\n",
    "    if adapter_name == \"lora\":\n",
    "        config = LoraConfig(\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=target_modules,\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "    elif adapter_name == \"bottleneck\":\n",
    "        config = BottleneckConfig(\n",
    "            bottleneck_size=bottleneck_size,\n",
    "            non_linearity=non_linearity,\n",
    "            adapter_dropout=adapter_dropout,\n",
    "            use_parallel_adapter=use_parallel_adapter,\n",
    "            use_adapterp=use_adapterp,\n",
    "            target_modules=target_modules,\n",
    "            scaling=scaling,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "    elif adapter_name == \"prefix-tuning\":\n",
    "        config = PrefixTuningConfig(\n",
    "            num_virtual_tokens=num_virtual_tokens,\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "    model = get_peft_model(model, config)\n",
    "    if adapter_name == \"prefix-tuning\":\n",
    "        model.to('cuda')\n",
    "\n",
    "    # if data_path.endswith(\".json\"):  # todo: support jsonl\n",
    "    #     data = load_dataset(\"json\", data_files=data_path)\n",
    "    # else:\n",
    "    #     data = load_dataset(data_path)\n",
    "        \n",
    "    \n",
    "    data = load_dataset('csv', data_files={'train': os.path.join(data_path,'train.csv'),\n",
    "                                            'val':os.path.join(data_path,'val.csv'),\n",
    "                                            'test': os.path.join(data_path,'test.csv')})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(data['train'])\n",
    "\n",
    "    if resume_from_checkpoint:\n",
    "        # Check the available weights and load them\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "        )  # Full checkpoint\n",
    "        if not os.path.exists(checkpoint_name):\n",
    "            checkpoint_name = os.path.join(\n",
    "                resume_from_checkpoint, \"adapter_model.bin\"\n",
    "            )  # only LoRA model - LoRA config above has to fit\n",
    "            resume_from_checkpoint = (\n",
    "                False  # So the trainer won't try loading its state\n",
    "            )\n",
    "        # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "        if os.path.exists(checkpoint_name):\n",
    "            print(f\"Restarting from {checkpoint_name}\")\n",
    "            adapters_weights = torch.load(checkpoint_name)\n",
    "            model = set_peft_model_state_dict(model, adapters_weights)\n",
    "        else:\n",
    "            print(f\"Checkpoint {checkpoint_name} not found\")\n",
    "\n",
    "    model.print_trainable_parameters()  # Be more transparent about the % of trainable params.\n",
    "\n",
    "    train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    val_data = data[\"val\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    \n",
    "    # if val_set_size > 0:\n",
    "    #     train_val = data[\"train\"].train_test_split(\n",
    "    #         test_size=val_set_size, shuffle=True, seed=42\n",
    "    #     )\n",
    "    #     train_data = (\n",
    "    #         train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    #     )\n",
    "    #     val_data = (\n",
    "    #         train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    #     )\n",
    "    # else:\n",
    "    #     train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    #     val_data = None\n",
    "\n",
    "    if not ddp and torch.cuda.device_count() > 1:\n",
    "        # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=micro_batch_size,\n",
    "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "            warmup_steps=100,\n",
    "            num_train_epochs=num_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            fp16=True,\n",
    "            logging_steps=10,\n",
    "            optim=\"adamw_torch\",\n",
    "            evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n",
    "            save_strategy=\"steps\",\n",
    "            eval_steps=eval_step if val_set_size > 0 else None,\n",
    "            save_steps=save_step,\n",
    "            output_dir=output_dir,\n",
    "            save_total_limit=3,\n",
    "            load_best_model_at_end=True if val_set_size > 0 else False,\n",
    "            ddp_find_unused_parameters=False if ddp else None,\n",
    "            group_by_length=group_by_length,\n",
    "            report_to=\"wandb\" if use_wandb else None,\n",
    "            run_name=wandb_run_name if use_wandb else None,\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "        ),\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "\n",
    "    old_state_dict = model.state_dict\n",
    "    model.state_dict = (\n",
    "        lambda self, *_, **__: get_peft_model_state_dict(\n",
    "            self, old_state_dict()\n",
    "        )\n",
    "    ).__get__(model, type(model))\n",
    "\n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "\n",
    "    print(\n",
    "        \"\\n If there's a warning about missing keys above, please disregard :)\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning model with params:\n",
      "base_model: bigscience/bloom-560m\n",
      "data_path: DataSplit/bloom\n",
      "output_dir: saved_models/finetune/adapter/4e-5/bloom-560m\n",
      "batch_size: 8\n",
      "micro_batch_size: 4\n",
      "num_epochs: 5\n",
      "learning_rate: 4e-05\n",
      "cutoff_len: 256\n",
      "val_set_size: 2000\n",
      "use_gradient_checkpointing: False\n",
      "lora_r: 8\n",
      "lora_alpha: 16\n",
      "lora_dropout: 0.05\n",
      "lora_target_modules: None\n",
      "bottleneck_size: 256\n",
      "non_linearity: tanh\n",
      "adapter_dropout: 0.0\n",
      "use_parallel_adapter: False\n",
      "use_adapterp: False\n",
      "train_on_inputs: True\n",
      "scaling: 1.0\n",
      "adapter_name: bottleneck\n",
      "target_modules: None\n",
      "group_by_length: False\n",
      "wandb_project: \n",
      "wandb_run_name: \n",
      "wandb_watch: \n",
      "wandb_log_model: \n",
      "resume_from_checkpoint: None\n",
      "\n",
      "trainable params: 25165824 || all params: 584380416 || trainable%: 4.306411253863785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21a837c16404362b434bc469dc2b965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5040 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0be29fdcd7c402795f35482d9c55f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahpon/miniconda3/envs/project_c2/lib/python3.9/site-packages/transformers/training_args.py:1493: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3150' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 1:00:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.479400</td>\n",
       "      <td>1.416715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.408800</td>\n",
       "      <td>1.352946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.283400</td>\n",
       "      <td>1.322341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.146000</td>\n",
       "      <td>1.300111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.309700</td>\n",
       "      <td>1.282642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.154200</td>\n",
       "      <td>1.268589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.131300</td>\n",
       "      <td>1.260974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.142200</td>\n",
       "      <td>1.250626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.136300</td>\n",
       "      <td>1.243758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.088000</td>\n",
       "      <td>1.241778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.085200</td>\n",
       "      <td>1.235687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.087800</td>\n",
       "      <td>1.232155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>1.232942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.114500</td>\n",
       "      <td>1.233178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.230315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['base_model.model.transformer.word_embeddings.weight', 'base_model.model.transformer.word_embeddings_layernorm.weight', 'base_model.model.transformer.word_embeddings_layernorm.bias', 'base_model.model.transformer.h.0.input_layernorm.weight', 'base_model.model.transformer.h.0.input_layernorm.bias', 'base_model.model.transformer.h.0.self_attention.query_key_value.weight', 'base_model.model.transformer.h.0.self_attention.query_key_value.bias', 'base_model.model.transformer.h.0.self_attention.dense.weight', 'base_model.model.transformer.h.0.self_attention.dense.bias', 'base_model.model.transformer.h.0.post_attention_layernorm.weight', 'base_model.model.transformer.h.0.post_attention_layernorm.bias', 'base_model.model.transformer.h.0.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.0.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.0.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.0.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.1.input_layernorm.weight', 'base_model.model.transformer.h.1.input_layernorm.bias', 'base_model.model.transformer.h.1.self_attention.query_key_value.weight', 'base_model.model.transformer.h.1.self_attention.query_key_value.bias', 'base_model.model.transformer.h.1.self_attention.dense.weight', 'base_model.model.transformer.h.1.self_attention.dense.bias', 'base_model.model.transformer.h.1.post_attention_layernorm.weight', 'base_model.model.transformer.h.1.post_attention_layernorm.bias', 'base_model.model.transformer.h.1.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.1.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.1.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.1.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.2.input_layernorm.weight', 'base_model.model.transformer.h.2.input_layernorm.bias', 'base_model.model.transformer.h.2.self_attention.query_key_value.weight', 'base_model.model.transformer.h.2.self_attention.query_key_value.bias', 'base_model.model.transformer.h.2.self_attention.dense.weight', 'base_model.model.transformer.h.2.self_attention.dense.bias', 'base_model.model.transformer.h.2.post_attention_layernorm.weight', 'base_model.model.transformer.h.2.post_attention_layernorm.bias', 'base_model.model.transformer.h.2.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.2.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.2.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.2.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.3.input_layernorm.weight', 'base_model.model.transformer.h.3.input_layernorm.bias', 'base_model.model.transformer.h.3.self_attention.query_key_value.weight', 'base_model.model.transformer.h.3.self_attention.query_key_value.bias', 'base_model.model.transformer.h.3.self_attention.dense.weight', 'base_model.model.transformer.h.3.self_attention.dense.bias', 'base_model.model.transformer.h.3.post_attention_layernorm.weight', 'base_model.model.transformer.h.3.post_attention_layernorm.bias', 'base_model.model.transformer.h.3.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.3.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.3.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.3.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.4.input_layernorm.weight', 'base_model.model.transformer.h.4.input_layernorm.bias', 'base_model.model.transformer.h.4.self_attention.query_key_value.weight', 'base_model.model.transformer.h.4.self_attention.query_key_value.bias', 'base_model.model.transformer.h.4.self_attention.dense.weight', 'base_model.model.transformer.h.4.self_attention.dense.bias', 'base_model.model.transformer.h.4.post_attention_layernorm.weight', 'base_model.model.transformer.h.4.post_attention_layernorm.bias', 'base_model.model.transformer.h.4.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.4.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.4.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.4.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.5.input_layernorm.weight', 'base_model.model.transformer.h.5.input_layernorm.bias', 'base_model.model.transformer.h.5.self_attention.query_key_value.weight', 'base_model.model.transformer.h.5.self_attention.query_key_value.bias', 'base_model.model.transformer.h.5.self_attention.dense.weight', 'base_model.model.transformer.h.5.self_attention.dense.bias', 'base_model.model.transformer.h.5.post_attention_layernorm.weight', 'base_model.model.transformer.h.5.post_attention_layernorm.bias', 'base_model.model.transformer.h.5.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.5.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.5.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.5.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.6.input_layernorm.weight', 'base_model.model.transformer.h.6.input_layernorm.bias', 'base_model.model.transformer.h.6.self_attention.query_key_value.weight', 'base_model.model.transformer.h.6.self_attention.query_key_value.bias', 'base_model.model.transformer.h.6.self_attention.dense.weight', 'base_model.model.transformer.h.6.self_attention.dense.bias', 'base_model.model.transformer.h.6.post_attention_layernorm.weight', 'base_model.model.transformer.h.6.post_attention_layernorm.bias', 'base_model.model.transformer.h.6.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.6.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.6.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.6.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.7.input_layernorm.weight', 'base_model.model.transformer.h.7.input_layernorm.bias', 'base_model.model.transformer.h.7.self_attention.query_key_value.weight', 'base_model.model.transformer.h.7.self_attention.query_key_value.bias', 'base_model.model.transformer.h.7.self_attention.dense.weight', 'base_model.model.transformer.h.7.self_attention.dense.bias', 'base_model.model.transformer.h.7.post_attention_layernorm.weight', 'base_model.model.transformer.h.7.post_attention_layernorm.bias', 'base_model.model.transformer.h.7.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.7.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.7.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.7.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.8.input_layernorm.weight', 'base_model.model.transformer.h.8.input_layernorm.bias', 'base_model.model.transformer.h.8.self_attention.query_key_value.weight', 'base_model.model.transformer.h.8.self_attention.query_key_value.bias', 'base_model.model.transformer.h.8.self_attention.dense.weight', 'base_model.model.transformer.h.8.self_attention.dense.bias', 'base_model.model.transformer.h.8.post_attention_layernorm.weight', 'base_model.model.transformer.h.8.post_attention_layernorm.bias', 'base_model.model.transformer.h.8.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.8.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.8.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.8.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.9.input_layernorm.weight', 'base_model.model.transformer.h.9.input_layernorm.bias', 'base_model.model.transformer.h.9.self_attention.query_key_value.weight', 'base_model.model.transformer.h.9.self_attention.query_key_value.bias', 'base_model.model.transformer.h.9.self_attention.dense.weight', 'base_model.model.transformer.h.9.self_attention.dense.bias', 'base_model.model.transformer.h.9.post_attention_layernorm.weight', 'base_model.model.transformer.h.9.post_attention_layernorm.bias', 'base_model.model.transformer.h.9.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.9.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.9.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.9.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.10.input_layernorm.weight', 'base_model.model.transformer.h.10.input_layernorm.bias', 'base_model.model.transformer.h.10.self_attention.query_key_value.weight', 'base_model.model.transformer.h.10.self_attention.query_key_value.bias', 'base_model.model.transformer.h.10.self_attention.dense.weight', 'base_model.model.transformer.h.10.self_attention.dense.bias', 'base_model.model.transformer.h.10.post_attention_layernorm.weight', 'base_model.model.transformer.h.10.post_attention_layernorm.bias', 'base_model.model.transformer.h.10.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.10.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.10.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.10.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.11.input_layernorm.weight', 'base_model.model.transformer.h.11.input_layernorm.bias', 'base_model.model.transformer.h.11.self_attention.query_key_value.weight', 'base_model.model.transformer.h.11.self_attention.query_key_value.bias', 'base_model.model.transformer.h.11.self_attention.dense.weight', 'base_model.model.transformer.h.11.self_attention.dense.bias', 'base_model.model.transformer.h.11.post_attention_layernorm.weight', 'base_model.model.transformer.h.11.post_attention_layernorm.bias', 'base_model.model.transformer.h.11.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.11.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.11.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.11.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.12.input_layernorm.weight', 'base_model.model.transformer.h.12.input_layernorm.bias', 'base_model.model.transformer.h.12.self_attention.query_key_value.weight', 'base_model.model.transformer.h.12.self_attention.query_key_value.bias', 'base_model.model.transformer.h.12.self_attention.dense.weight', 'base_model.model.transformer.h.12.self_attention.dense.bias', 'base_model.model.transformer.h.12.post_attention_layernorm.weight', 'base_model.model.transformer.h.12.post_attention_layernorm.bias', 'base_model.model.transformer.h.12.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.12.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.12.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.12.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.13.input_layernorm.weight', 'base_model.model.transformer.h.13.input_layernorm.bias', 'base_model.model.transformer.h.13.self_attention.query_key_value.weight', 'base_model.model.transformer.h.13.self_attention.query_key_value.bias', 'base_model.model.transformer.h.13.self_attention.dense.weight', 'base_model.model.transformer.h.13.self_attention.dense.bias', 'base_model.model.transformer.h.13.post_attention_layernorm.weight', 'base_model.model.transformer.h.13.post_attention_layernorm.bias', 'base_model.model.transformer.h.13.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.13.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.13.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.13.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.14.input_layernorm.weight', 'base_model.model.transformer.h.14.input_layernorm.bias', 'base_model.model.transformer.h.14.self_attention.query_key_value.weight', 'base_model.model.transformer.h.14.self_attention.query_key_value.bias', 'base_model.model.transformer.h.14.self_attention.dense.weight', 'base_model.model.transformer.h.14.self_attention.dense.bias', 'base_model.model.transformer.h.14.post_attention_layernorm.weight', 'base_model.model.transformer.h.14.post_attention_layernorm.bias', 'base_model.model.transformer.h.14.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.14.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.14.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.14.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.15.input_layernorm.weight', 'base_model.model.transformer.h.15.input_layernorm.bias', 'base_model.model.transformer.h.15.self_attention.query_key_value.weight', 'base_model.model.transformer.h.15.self_attention.query_key_value.bias', 'base_model.model.transformer.h.15.self_attention.dense.weight', 'base_model.model.transformer.h.15.self_attention.dense.bias', 'base_model.model.transformer.h.15.post_attention_layernorm.weight', 'base_model.model.transformer.h.15.post_attention_layernorm.bias', 'base_model.model.transformer.h.15.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.15.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.15.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.15.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.16.input_layernorm.weight', 'base_model.model.transformer.h.16.input_layernorm.bias', 'base_model.model.transformer.h.16.self_attention.query_key_value.weight', 'base_model.model.transformer.h.16.self_attention.query_key_value.bias', 'base_model.model.transformer.h.16.self_attention.dense.weight', 'base_model.model.transformer.h.16.self_attention.dense.bias', 'base_model.model.transformer.h.16.post_attention_layernorm.weight', 'base_model.model.transformer.h.16.post_attention_layernorm.bias', 'base_model.model.transformer.h.16.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.16.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.16.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.16.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.17.input_layernorm.weight', 'base_model.model.transformer.h.17.input_layernorm.bias', 'base_model.model.transformer.h.17.self_attention.query_key_value.weight', 'base_model.model.transformer.h.17.self_attention.query_key_value.bias', 'base_model.model.transformer.h.17.self_attention.dense.weight', 'base_model.model.transformer.h.17.self_attention.dense.bias', 'base_model.model.transformer.h.17.post_attention_layernorm.weight', 'base_model.model.transformer.h.17.post_attention_layernorm.bias', 'base_model.model.transformer.h.17.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.17.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.17.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.17.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.18.input_layernorm.weight', 'base_model.model.transformer.h.18.input_layernorm.bias', 'base_model.model.transformer.h.18.self_attention.query_key_value.weight', 'base_model.model.transformer.h.18.self_attention.query_key_value.bias', 'base_model.model.transformer.h.18.self_attention.dense.weight', 'base_model.model.transformer.h.18.self_attention.dense.bias', 'base_model.model.transformer.h.18.post_attention_layernorm.weight', 'base_model.model.transformer.h.18.post_attention_layernorm.bias', 'base_model.model.transformer.h.18.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.18.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.18.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.18.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.19.input_layernorm.weight', 'base_model.model.transformer.h.19.input_layernorm.bias', 'base_model.model.transformer.h.19.self_attention.query_key_value.weight', 'base_model.model.transformer.h.19.self_attention.query_key_value.bias', 'base_model.model.transformer.h.19.self_attention.dense.weight', 'base_model.model.transformer.h.19.self_attention.dense.bias', 'base_model.model.transformer.h.19.post_attention_layernorm.weight', 'base_model.model.transformer.h.19.post_attention_layernorm.bias', 'base_model.model.transformer.h.19.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.19.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.19.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.19.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.20.input_layernorm.weight', 'base_model.model.transformer.h.20.input_layernorm.bias', 'base_model.model.transformer.h.20.self_attention.query_key_value.weight', 'base_model.model.transformer.h.20.self_attention.query_key_value.bias', 'base_model.model.transformer.h.20.self_attention.dense.weight', 'base_model.model.transformer.h.20.self_attention.dense.bias', 'base_model.model.transformer.h.20.post_attention_layernorm.weight', 'base_model.model.transformer.h.20.post_attention_layernorm.bias', 'base_model.model.transformer.h.20.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.20.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.20.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.20.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.21.input_layernorm.weight', 'base_model.model.transformer.h.21.input_layernorm.bias', 'base_model.model.transformer.h.21.self_attention.query_key_value.weight', 'base_model.model.transformer.h.21.self_attention.query_key_value.bias', 'base_model.model.transformer.h.21.self_attention.dense.weight', 'base_model.model.transformer.h.21.self_attention.dense.bias', 'base_model.model.transformer.h.21.post_attention_layernorm.weight', 'base_model.model.transformer.h.21.post_attention_layernorm.bias', 'base_model.model.transformer.h.21.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.21.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.21.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.21.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.22.input_layernorm.weight', 'base_model.model.transformer.h.22.input_layernorm.bias', 'base_model.model.transformer.h.22.self_attention.query_key_value.weight', 'base_model.model.transformer.h.22.self_attention.query_key_value.bias', 'base_model.model.transformer.h.22.self_attention.dense.weight', 'base_model.model.transformer.h.22.self_attention.dense.bias', 'base_model.model.transformer.h.22.post_attention_layernorm.weight', 'base_model.model.transformer.h.22.post_attention_layernorm.bias', 'base_model.model.transformer.h.22.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.22.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.22.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.22.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.h.23.input_layernorm.weight', 'base_model.model.transformer.h.23.input_layernorm.bias', 'base_model.model.transformer.h.23.self_attention.query_key_value.weight', 'base_model.model.transformer.h.23.self_attention.query_key_value.bias', 'base_model.model.transformer.h.23.self_attention.dense.weight', 'base_model.model.transformer.h.23.self_attention.dense.bias', 'base_model.model.transformer.h.23.post_attention_layernorm.weight', 'base_model.model.transformer.h.23.post_attention_layernorm.bias', 'base_model.model.transformer.h.23.mlp.dense_h_to_4h.weight', 'base_model.model.transformer.h.23.mlp.dense_h_to_4h.bias', 'base_model.model.transformer.h.23.mlp.dense_4h_to_h.weight', 'base_model.model.transformer.h.23.mlp.dense_4h_to_h.bias', 'base_model.model.transformer.ln_f.weight', 'base_model.model.transformer.ln_f.bias', 'base_model.model.lm_head.0.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " If there's a warning about missing keys above, please disregard :)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # fire.Fire(train)\n",
    "    train(base_model='bigscience/bloom-560m', data_path='DataSplit/bloom', output_dir='saved_models/finetune/adapter/4e-5/bloom-560m', adapter_name='bottleneck', learning_rate=4e-5, batch_size=8, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rahpon/projects/caste\n"
     ]
    }
   ],
   "source": [
    "#  Setting the working directory\n",
    "import os\n",
    "if os.getcwd() != '/home/rahpon/projects/caste':\n",
    "    os.chdir('/home/rahpon/projects/caste')\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import fire\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"LLM-Adapters/peft/src\"))\n",
    "from peft import PeftModel\n",
    "from peft import (  # noqa: E402\n",
    "    LoraConfig,\n",
    "    BottleneckConfig,\n",
    "    PrefixTuningConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoModelForSequenceClassification, AutoModel\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "except:  # noqa: E722\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dir(dir_path):\n",
    "#     if not os.path.exists(dir_path):\n",
    "#         os.mkdir(dir_path)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, input=None):\n",
    "    # if input:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "                ### Instruction:\n",
    "                {instruction}\n",
    "\n",
    "                ### Input:\n",
    "                {input}\n",
    "\n",
    "                ### Response:\n",
    "                \"\"\"  # noqa: E501\n",
    "    # else:\n",
    "    #     return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. \n",
    "\n",
    "    #             ### Instruction:\n",
    "    #             {instruction}\n",
    "\n",
    "    #             ### Response:\n",
    "    #             \"\"\"  # noqa: E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(args) -> list:\n",
    "#     \"\"\"\n",
    "#     read data from dataset file\n",
    "#     Args:\n",
    "#         args:\n",
    "\n",
    "#     Returns:\n",
    "\n",
    "#     \"\"\"\n",
    "#     file_path = f'dataset/{args.dataset}/test.json'\n",
    "#     if not os.path.exists(file_path):\n",
    "#         raise FileNotFoundError(f\"can not find dataset file : {file_path}\")\n",
    "#     json_data = json.load(open(file_path, 'r'))\n",
    "#     return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--dataset', choices=['AddSub', 'MultiArith', 'SingleEq', 'gsm8k', 'AQuA', 'SVAMP'],\n",
    "#                         required=True)\n",
    "#     parser.add_argument('--model', choices=['LLaMA-7B', 'BLOOM-7B', 'GPT-j-6B'], required=True)\n",
    "#     parser.add_argument('--adapter', choices=['LoRA', 'AdapterP', 'AdapterH', 'Parallel', 'Prefix'],\n",
    "#                         required=True)\n",
    "#     parser.add_argument('--base_model', required=True)\n",
    "#     parser.add_argument('--lora_weights', required=True)\n",
    "#     parser.add_argument('--load_8bit', action='store_true', default=False)\n",
    "\n",
    "#     return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(base_model) -> tuple:\n",
    "    \"\"\"\n",
    "    load tuned model\n",
    "    Args:\n",
    "        args:\n",
    "\n",
    "    Returns:\n",
    "        tuple(tokenizer, model)\n",
    "    \"\"\"\n",
    "    # base_model = args.base_model\n",
    "    # if not base_model:\n",
    "    #     raise ValueError(f'can not find base model name by the value: {args.model}')\n",
    "    # lora_weights = args.lora_weights\n",
    "    # if not lora_weights:\n",
    "    #     raise ValueError(f'can not find lora weight, the value is: {lora_weights}')\n",
    "\n",
    "    # load_8bit = args.load_8bit\n",
    "    # if args.model == 'LLaMA-7B':\n",
    "    #     tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "    # else:\n",
    "    \n",
    "    \n",
    "    # tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "    tokenizer.pad_token_id = (0)\n",
    "    tokenizer.padding_side = \"left\"  # Allow batched inference\n",
    "    \n",
    "    # Quantization Config\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "                                    load_in_8bit=True,\n",
    "                                    bnb_4bit_quant_type=\"fp4\",\n",
    "                                    bnb_4bit_use_double_quant=False,\n",
    "                                    bnb_4bit_compute_dtype=torch.float16\n",
    "                                    )\n",
    "    \n",
    "    # if device == \"cuda\":\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        # load_in_8bit=False,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quant_config\n",
    "    ) # fix zwq\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # model = PeftModel.from_pretrained(\n",
    "    #     model,\n",
    "    #     lora_weights,\n",
    "    #     torch_dtype=torch.float16,\n",
    "    #     device_map={\"\":0}\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    # else:\n",
    "    #     model = AutoModelForCausalLM.from_pretrained(\n",
    "    #         base_model, device_map={\"\": device}, low_cpu_mem_usage=True\n",
    "    #     )\n",
    "    #     model = PeftModel.from_pretrained(\n",
    "    #         model,\n",
    "    #         lora_weights,\n",
    "    #         device_map={\"\": device},\n",
    "    #     )\n",
    "        \n",
    "    \n",
    "    \n",
    "    ##############  sample code  #########################################################\n",
    "    \n",
    "    # model/data params\n",
    "    # bottleneck adapter hyperparams\n",
    "    bottleneck_size: int = 256\n",
    "    non_linearity: str = \"tanh\"\n",
    "    adapter_dropout: float = 0.0\n",
    "    use_parallel_adapter: bool = False\n",
    "    use_adapterp: bool = False\n",
    "    target_modules: List[str] = None\n",
    "    scaling: Union[float, str] = 1.0\n",
    "    \n",
    "    \n",
    "    model = prepare_model_for_int8_training(model, use_gradient_checkpointing=True)\n",
    "    config = BottleneckConfig(\n",
    "            bottleneck_size=bottleneck_size,\n",
    "            non_linearity=non_linearity,\n",
    "            adapter_dropout=adapter_dropout,\n",
    "            use_parallel_adapter=use_parallel_adapter,\n",
    "            use_adapterp=use_adapterp,\n",
    "            target_modules=target_modules,\n",
    "            scaling=scaling,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "    model = get_peft_model(model, config)\n",
    "    \n",
    "    \n",
    "    # adapters_weights = torch.load(checkpoint_name)\n",
    "    checkpoint_name = os.path.join(\"saved_models/finetune/adapter/4e-5/bloom-560m\", \"adapter_model.bin\")\n",
    "    adapters_weights = torch.load(checkpoint_name)\n",
    "    model = set_peft_model_state_dict(model, adapters_weights)\n",
    "    print(model)\n",
    "    \n",
    "    \n",
    "    # model = get_peft_model_state_dict(model, adapters_weights)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # if resume_from_checkpoint:\n",
    "    # # Check the available weights and load them\n",
    "    #     checkpoint_name = os.path.join(\n",
    "    #         resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "    #     )  # Full checkpoint\n",
    "    #     # if not os.path.exists(checkpoint_name):\n",
    "    #     #     checkpoint_name = os.path.join(\n",
    "    #     #         resume_from_checkpoint, \"adapter_model.bin\"\n",
    "    #     #     )  # only LoRA model - LoRA config above has to fit\n",
    "    #     #     resume_from_checkpoint = (\n",
    "    #     #         False  # So the trainer won't try loading its state\n",
    "    #     #     )\n",
    "    #     # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "    #     if os.path.exists(checkpoint_name):\n",
    "    #         # print(f\"Restarting from {checkpoint_name}\")\n",
    "    #         adapters_weights = torch.load(checkpoint_name)\n",
    "    #         model = set_peft_model_state_dict(model, adapters_weights)\n",
    "    #     else:\n",
    "    #         print(f\"Checkpoint {checkpoint_name} not found\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # unwind broken decapoda-research config\n",
    "    # model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "    # model.config.bos_token_id = 1\n",
    "    # model.config.eos_token_id = 2\n",
    "\n",
    "    # if not load_8bit:\n",
    "    #     model.half()  # seems to fix bugs for some users.\n",
    "\n",
    "    model.eval()\n",
    "    if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_instruction(args) -> str:\n",
    "#     instruction = ''\n",
    "#     if not instruction:\n",
    "#         raise ValueError('instruct not initialized')\n",
    "#     return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_number(sentence: str) -> float:\n",
    "    # dataset = dataset.lower()\n",
    "    # if dataset in [\"multiarith\", \"addsub\", \"singleeq\", \"gsm8k\", \"svamp\"]:\n",
    "    sentence = sentence.replace(',', '')\n",
    "    pred = [s for s in re.findall(r'-?\\d+\\.?\\d*', sentence)]\n",
    "    if not pred:\n",
    "        return float('inf')\n",
    "    pred_answer = float(pred[-1])\n",
    "    if isinstance(pred_answer, str):\n",
    "        try:\n",
    "            pred_answer = float(pred_answer)\n",
    "        except ValueError as e:\n",
    "            pred_answer = float('inf')\n",
    "    return pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_answer_letter(args, sentence: str) -> str:\n",
    "#     sentence_ = sentence.strip()\n",
    "#     pred_answers = re.findall(r'A|B|C|D|E', sentence_)\n",
    "#     if pred_answers:\n",
    "#         if not pred_answers:\n",
    "#             return ''\n",
    "#         return pred_answers[0]\n",
    "#     else:\n",
    "#         return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "        load_8bit: bool = False,\n",
    "        base_model: str = \"\",\n",
    "        data_path: str = \"DataSplit/bloom\",\n",
    "        lora_weights: str = \"tloen/alpaca-lora-7b\",\n",
    "        share_gradio: bool = False,\n",
    "):\n",
    "    # args = parse_args()\n",
    "\n",
    "    def evaluate(\n",
    "            instruction,\n",
    "            input=None,\n",
    "            temperature=0.1,\n",
    "            top_p=0.75,\n",
    "            top_k=40,\n",
    "            num_beams=4,\n",
    "            max_new_tokens=256,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        prompt = generate_prompt(instruction, input)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            num_beams=num_beams,\n",
    "            **kwargs,\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            generation_output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                generation_config=generation_config,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                use_cache=False,\n",
    "            )\n",
    "        s = generation_output.sequences[0]\n",
    "        output = tokenizer.decode(s)\n",
    "        return output.split(\"### Response:\")[1].strip()\n",
    "\n",
    "    \"\"\"\n",
    "    # testing code for readme\n",
    "    for instruction in [\n",
    "        \"Tell me about alpacas.\",\n",
    "        \"Tell me about the president of Mexico in 2019.\",\n",
    "        \"Tell me about the king of France in 2019.\",\n",
    "        \"List all Canadian provinces in alphabetical order.\",\n",
    "        \"Write a Python program that prints the first 10 Fibonacci numbers.\",\n",
    "        \"Write a program that prints the numbers from 1 to 100. But for multiples of three print 'Fizz' instead of the number and for the multiples of five print 'Buzz'. For numbers which are multiples of both three and five print 'FizzBuzz'.\",  # noqa: E501\n",
    "        \"Tell me five words that rhyme with 'shock'.\",\n",
    "        \"Translate the sentence 'I have no mouth but I must scream' into Spanish.\",\n",
    "        \"Count up from 1 to 500.\",\n",
    "    ]:\n",
    "        print(\"Instruction:\", instruction)\n",
    "        print(\"Response:\", evaluate(instruction))\n",
    "        print()\n",
    "    \"\"\"\n",
    "    save_file = f'saved_models/finetune/adapter/4e-5/bloom-560m/results.json'\n",
    "    # create_dir('experiment/')\n",
    "\n",
    "    # dataset = load_data(args)\n",
    "    dataset = load_dataset('csv', data_files={'test': os.path.join(data_path,'test.csv')})\n",
    "    \n",
    "    \n",
    "    tokenizer, model = load_model(base_model)\n",
    "    total = len(dataset)\n",
    "    correct = 0\n",
    "    miss = 0.001\n",
    "    output_data = []\n",
    "    pbar = tqdm(total=total)\n",
    "    for idx, data in tqdm(enumerate(dataset['test'])):\n",
    "        # print(data)\n",
    "        instruction = data.get('instruction')\n",
    "        input = data.get('texts')\n",
    "\n",
    "        outputs = evaluate(instruction,input)\n",
    "        label = data.get('labels')\n",
    "        flag = False\n",
    "        # if args.dataset.lower() in ['aqua']:\n",
    "        #     predict = extract_answer_letter(args, outputs)\n",
    "        #     if label == predict:\n",
    "        #         correct += 1\n",
    "        #         flag = True\n",
    "        # else:\n",
    "        if isinstance(label, str):\n",
    "            label = float(label)\n",
    "        predict = extract_answer_number(outputs)\n",
    "        if abs(label - predict) <= miss:\n",
    "            correct += 1\n",
    "            flag = True\n",
    "        new_data = copy.deepcopy(data)\n",
    "        new_data['output_pred'] = outputs\n",
    "        new_data['pred'] = predict\n",
    "        new_data['flag'] = flag\n",
    "        output_data.append(new_data)\n",
    "        print(' ')\n",
    "        print('---------------')\n",
    "        print(outputs)\n",
    "        print('prediction:', predict)\n",
    "        print('label:', label)\n",
    "        print('---------------')\n",
    "        print(f'\\rtest:{idx + 1}/{total} | accuracy {correct}  {correct / (idx + 1)}')\n",
    "        with open(save_file, 'w+') as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    print('\\n')\n",
    "    print('test finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): BottleneckModel(\n",
      "    (model): BloomForCausalLM(\n",
      "      (transformer): BloomModel(\n",
      "        (word_embeddings): Embedding(250880, 1024)\n",
      "        (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (h): ModuleList(\n",
      "          (0-23): 24 x BloomBlock(\n",
      "            (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (self_attention): BloomAttention(\n",
      "              (query_key_value): Linear8bitLt(in_features=1024, out_features=3072, bias=True)\n",
      "              (dense): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): BloomMLP(\n",
      "              (dense_h_to_4h): Linear8bitLt(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (adapter_down): Linear(in_features=1024, out_features=256, bias=False)\n",
      "                (adapter_up): Linear(in_features=256, out_features=1024, bias=False)\n",
      "                (act_fn): Tanh()\n",
      "              )\n",
      "              (gelu_impl): BloomGelu()\n",
      "              (dense_4h_to_h): Linear8bitLt(\n",
      "                in_features=1024, out_features=1024, bias=True\n",
      "                (adapter_down): Linear(in_features=1024, out_features=256, bias=False)\n",
      "                (adapter_up): Linear(in_features=256, out_features=1024, bias=False)\n",
      "                (act_fn): Tanh()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): CastOutputToFloat(\n",
      "        (0): Linear(in_features=1024, out_features=250880, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------\n",
      "1</s><?php\n",
      "/**\n",
      " * @package     Joomla.Administrator\n",
      " * @subpackage  com_contact\n",
      " *\n",
      " * @copyright   Copyright (C) 2005 - 2017 Open Source Matters, Inc. All rights reserved.\n",
      " * @license     GNU General Public License version 2 or later; see LICENSE.txt\n",
      " */\n",
      "\n",
      "defined('_JEXEC') or die;\n",
      "\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.formvalidator');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal\n",
      "prediction: 2.0\n",
      "label: 0\n",
      "---------------\n",
      "test:1/1 | accuracy 0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------\n",
      "1</s><?php\n",
      "/**\n",
      " * @package     Joomla.Administrator\n",
      " * @subpackage  com_contact\n",
      " *\n",
      " * @copyright   Copyright (C) 2005 - 2017 Open Source Matters, Inc. All rights reserved.\n",
      " * @license     GNU General Public License version 2 or later; see LICENSE.txt\n",
      " */\n",
      "\n",
      "defined('_JEXEC') or die;\n",
      "\n",
      "JHtml::addIncludePath(JPATH_COMPONENT . '/helpers');\n",
      "\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.formvalidator');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "prediction: 2.0\n",
      "label: 0\n",
      "---------------\n",
      "test:2/1 | accuracy 0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------\n",
      "0</s>à®¨à®•à¯ˆ à®•à¯Šà®³à¯à®³à¯ˆ à®µà®´à®•à¯à®•à®¿à®²à¯ à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®© à®µà®´à®•à¯à®•à®±à®¿à®žà®°à¯ à®°à®¾à®œà¯‡à®¨à¯à®¤à®¿à®°à®©à¯, â€œà®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®© à®µà®´à®•à¯à®•à®±à®¿à®žà®°à¯, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®šà®šà®¿à®•à®²à®¾ à®¤à®°à®ªà¯à®ªà¯ à®šà®¾à®°à¯à®ªà®¿à®²à¯ à®†à®œà®°à®¾à®©, à®š\n",
      "prediction: 0.0\n",
      "label: 1\n",
      "---------------\n",
      "test:3/1 | accuracy 0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------\n",
      "0</s><?php\n",
      "/* vim: set expandtab sw=4 ts=4 sts=4: */\n",
      "/**\n",
      " * File containing the eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\n",
      " *\n",
      " * @copyright  Copyright (C) eZ Systems AS. All rights reserved.\n",
      " * @license    GNU General Public License v2. Ø£Ùˆ later, see LICENSE file for license details.\n",
      " */\n",
      "\n",
      "namespace eZ\\Publish\\API\\Repository\\Values;\n",
      "\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\Operator;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\SortOrder;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\SortDirection;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\Version;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\VersionRange;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\Content\\Query\\Criterion\\VersionRange;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\User\\Content;\n",
      "use eZ\\Publish\\API\\Repository\\Values\\User\\User;\n",
      "use eZ\\Publish\n",
      "prediction: 2.0\n",
      "label: 0\n",
      "---------------\n",
      "test:4/1 | accuracy 0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "---------------\n",
      "1</s><?php\n",
      "/**\n",
      " * @package     Joomla.Administrator\n",
      " * @subpackage  com_contact\n",
      " *\n",
      " * @copyright   Copyright (C) 2005 - 2017 Open Source Matters, Inc. All rights reserved.\n",
      " * @license     GNU General Public License version 2 or later; see LICENSE.txt\n",
      " */\n",
      "\n",
      "defined('_JEXEC') or die;\n",
      "\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.formvalidator');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.keepalive');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal');\n",
      "JHtml::_('behavior.modal')\n",
      "prediction: 2.0\n",
      "label: 0\n",
      "---------------\n",
      "test:5/1 | accuracy 0  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [12:07, 145.40s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.71 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# fire.Fire(main)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbigscience/bloom-560m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshare_gradio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 78\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(load_8bit, base_model, data_path, lora_weights, share_gradio)\u001b[0m\n\u001b[1;32m     75\u001b[0m instruction \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m, in \u001b[0;36mmain.<locals>.evaluate\u001b[0;34m(instruction, input, temperature, top_p, top_k, num_beams, max_new_tokens, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     24\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     25\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     generation_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m s \u001b[38;5;241m=\u001b[39m generation_output\u001b[38;5;241m.\u001b[39msequences[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(s)\n",
      "File \u001b[0;32m~/projects/caste/LLM-Adapters/peft/src/peft/peft_model.py:585\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config, PromptLearningConfig):\n\u001b[0;32m--> 585\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/transformers/generation/utils.py:1861\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1854\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1855\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1856\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1857\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1858\u001b[0m     )\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1861\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1869\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1870\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1875\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1876\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1882\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1883\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/transformers/generation/utils.py:2720\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[1;32m   2719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 2720\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2723\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2724\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2728\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py:861\u001b[0m, in \u001b[0;36mBloomForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    848\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[1;32m    849\u001b[0m     input_ids,\n\u001b[1;32m    850\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    858\u001b[0m )\n\u001b[1;32m    859\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 861\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;66;03m# move labels to correct device to enable model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/project_c2/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/caste/LLM-Adapters/peft/src/peft/utils/other.py:82\u001b[0m, in \u001b[0;36mprepare_model_for_int8_training.<locals>.CastOutputToFloat.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.71 GiB. GPU "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # fire.Fire(main)\n",
    "    main(load_8bit=False, base_model='bigscience/bloom-560m', share_gradio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahpon/miniconda3/envs/project_c1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments,Trainer, AutoConfig, EvalPrediction\n",
    "from adapters import AdapterTrainer, AdapterSetup, AutoAdapterModel\n",
    "import adapters\n",
    "import adapters.composition as ac\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#######################################\n",
    "lr = 4e-5\n",
    "root = os.path.join(\"saved_models/finetune/adapter\",str(lr))\n",
    "sub_dir =\"bloom-560m\"\n",
    "output_path = os.path.join(root,sub_dir)\n",
    "model_path = 'bigscience/bloom-560m'\n",
    "########################################\n",
    "# model,tokenizer = classifier(model_path,output_path,lr)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "# root_dir = 'fine-tuning-6'\n",
    "# sub_dir = 'tamil-llama'\n",
    "# model_path = 'abhinand/tamil-llama-7b-base-v0.1'\n",
    "# lr = 1e-5\n",
    "\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5040/5040 [00:00<00:00, 15854.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1260/1260 [00:00<00:00, 15707.51 examples/s]\n",
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_adapter() got an unexpected keyword argument 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 63\u001b[0m\n\u001b[1;32m     53\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# config = AutoConfig.from_pretrained(\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     model_path,\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     num_labels=2,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#     # config=config,\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-adapter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq_bn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# seq_bn is a Bottleneck adapter. link: https://docs.adapterhub.ml/methods.html#bottleneck-adapters\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Add a matching classification head\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# model.add_classification_head(\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#     sub_dir+\"-adapter\",\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#     num_labels=2,\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Activate the adapter\u001b[39;00m\n\u001b[1;32m     70\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_adapter(sub_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: add_adapter() got an unexpected keyword argument 'config'"
     ]
    }
   ],
   "source": [
    "# def classifier(model_path, output_path, lr):\n",
    "logs_dir = os.path.join(output_path, 'logs')\n",
    "\n",
    "# model_name_or_path = model_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path,\n",
    "                                            padding_side=\"left\")  # will have to be changed depending on model, left for gpt opt bloom\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    outputs = tokenizer(examples[\"texts\"], truncation=True, max_length=250)\n",
    "    return outputs\n",
    "\n",
    "train_pd = pd.read_csv(r'DataSplit/train.csv')\n",
    "val_pd = pd.read_csv(r'DataSplit/val.csv')\n",
    "\n",
    "# Converting the pandas dataframe to HuggingFace DatasetDict format:\n",
    "train_ds = Dataset.from_pandas(train_pd)\n",
    "\n",
    "val_ds = Dataset.from_pandas(val_pd)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_ds.map(tokenize_function, batched=True)\n",
    "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
    "tokenized_val = tokenized_val.rename_column(\"label\", \"labels\")\n",
    "\n",
    "\n",
    "#####################################\n",
    "# config = AutoConfig.from_pretrained(\n",
    "#     model_path,\n",
    "#     num_labels=2,\n",
    "# )\n",
    "# model = AutoModelWithHeads.from_pretrained(\n",
    "#     model_path,\n",
    "#     config=config,\n",
    "# )\n",
    "\n",
    "# # Add a new adapter\n",
    "# model.add_adapter(\"tamil-muril-large\")\n",
    "# # Add a matching classification head\n",
    "# model.add_classification_head(\n",
    "#     \"tamil-muril-large\",\n",
    "#     num_labels=2,\n",
    "# )\n",
    "# # Activate the adapter\n",
    "# model.train_adapter(\"tamil-olid-muril-large\")\n",
    "##########################################\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, return_dict=True)\n",
    "# config = AutoConfig.from_pretrained(\n",
    "#     model_path,\n",
    "#     num_labels=2,\n",
    "# )\n",
    "# model = AutoAdapterModel.from_pretrained(\n",
    "#     model_path,\n",
    "#     # config=config,\n",
    "# )\n",
    "\n",
    "model.add_adapter(sub_dir+\"-adapter\", config='seq_bn')  # seq_bn is a Bottleneck adapter. link: https://docs.adapterhub.ml/methods.html#bottleneck-adapters\n",
    "# Add a matching classification head\n",
    "# model.add_classification_head(\n",
    "#     sub_dir+\"-adapter\",\n",
    "#     num_labels=2,\n",
    "# )\n",
    "# Activate the adapter\n",
    "model.train_adapter(sub_dir+\"-adapter\")\n",
    "\n",
    "# model.set_default_language(\"ta_IN\") #only for xmod\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_path,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",  # Evaluate at specified steps\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_steps=600,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=logs_dir,  # tensorboard\n",
    "    # save_total_limit=5,\n",
    "    # report_to = \"wandb\"\n",
    ")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_train,\n",
    "#     eval_dataset=tokenized_val,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "# compute train results\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = len(tokenized_train)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(tokenized_train))\n",
    "\n",
    "# save train results\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "\n",
    "trainer.save_model(training_args.output_dir)  # Saves model and associated tokenizer\n",
    "\n",
    "# model.save_pretrained(training_args.output_dir)\n",
    "\n",
    "losses = trainer.state.log_history\n",
    "# print(\"trainer.state.log_history: \")\n",
    "# print(losses)\n",
    "training_loss_path = os.path.join(output_path, \"training_loss.json\")\n",
    "eval_loss_path = os.path.join(output_path, \"eval_loss.json\")\n",
    "training_losses = [entry for entry in losses if 'loss' in entry]\n",
    "eval_losses = [entry for entry in losses if 'eval_loss' in entry]\n",
    "with open(training_loss_path, 'w') as f:\n",
    "    json.dump(training_losses, f, indent=2)\n",
    "with open(eval_loss_path, 'w') as f:\n",
    "    json.dump(eval_losses, f, indent=2)\n",
    "# return model,tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[973   0]\n",
      " [602   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       973\n",
      "           1       0.00      0.00      0.00       602\n",
      "\n",
      "    accuracy                           0.62      1575\n",
      "   macro avg       0.31      0.50      0.38      1575\n",
      "weighted avg       0.38      0.62      0.47      1575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predictions\"\"\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# peft_model_id = output_path\n",
    "# config = PeftConfig.from_pretrained(peft_model_id)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "# model = PeftModel.from_pretrained(inference_model, peft_model_id)\n",
    "\n",
    "test_data_path = r\"DataSplit/test.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_texts = test_data['texts'].tolist()\n",
    "\n",
    "predictions_df = test_texts\n",
    "\n",
    "tokenized_test = tokenizer(test_texts, truncation=True, padding=True, return_tensors='pt',max_length = 250)\n",
    "model.to('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(**tokenized_test)\n",
    "\n",
    "logits = outputs.logits\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "predicted_labels = torch.argmax(probs, dim=-1).tolist()\n",
    "\n",
    "predictions_df = test_data\n",
    "\n",
    "predictions_df['predictions'] = predicted_labels\n",
    "\n",
    "labels = test_data['labels'].tolist()\n",
    "\n",
    "conf_matrix = confusion_matrix(predictions_df['labels'], predictions_df['predictions'])\n",
    "\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(labels, predicted_labels)\n",
    "\n",
    "print(class_report)\n",
    "\n",
    "predictions_path = os.path.join(output_path,'predictions.csv')\n",
    "\n",
    "predictions_df.to_csv(predictions_path)\n",
    "\n",
    "metrics_path = os.path.join(output_path,\"metrics.txt\")\n",
    "\n",
    "with open(metrics_path,'a') as f:\n",
    "  f.write(\"Adapter_FT\")\n",
    "  f.write(\"learning rate: \")\n",
    "  f.write(str(lr))\n",
    "  f.write(model_path)\n",
    "  f.write(\"\\n\")\n",
    "  f.write(class_report)\n",
    "  f.write(\"Confusion Matric:\\n\")\n",
    "  np.savetxt(f,conf_matrix,fmt = \"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Saving Loss plots\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "train_loss_path = os.path.join(output_path,\"training_loss.json\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open(train_loss_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting values for plotting\n",
    "epochs = [entry['epoch'] for entry in data]\n",
    "losses = [entry['loss'] for entry in data]\n",
    "\n",
    "# Plotting the training losses over epochs\n",
    "plt.plot(epochs, losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "loss_plot_path = os.path.join(output_path,'training_loss_plot.png')\n",
    "plt.savefig(loss_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Saving Loss plots\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "train_loss_path = os.path.join(output_path,\"eval_loss.json\")\n",
    "\n",
    "# Load the JSON file\n",
    "with open(train_loss_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting values for plotting\n",
    "epochs = [entry['epoch'] for entry in data]\n",
    "losses = [entry['eval_loss'] for entry in data]\n",
    "\n",
    "# Plotting the training losses over epochs\n",
    "plt.plot(epochs, losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Evaluation Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "loss_plot_path = os.path.join(output_path,'eval_loss_plot.png')\n",
    "plt.savefig(loss_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
